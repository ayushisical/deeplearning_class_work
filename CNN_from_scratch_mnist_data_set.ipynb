{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXaGTG8Gypfl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k33xYaJHhwsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK-7QlY4bnJu"
      },
      "source": [
        " CONVOLUTION LAYER WITH BACK AND FORWARD PROP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3XzRL1iypab"
      },
      "outputs": [],
      "source": [
        "class Conv_op:\n",
        "  def __init__(self,num_filters,filter_size):\n",
        "    self.num_filters = num_filters\n",
        "    self.filter_size = filter_size\n",
        "    self.conv_filter = np.random.randn(num_filters, filter_size,filter_size)/(filter_size*filter_size)\n",
        "\n",
        "  def image_region(self, image):\n",
        "    height,width =  image.shape\n",
        "    self.image = image\n",
        "    for j in range(height - self.filter_size +1 ):\n",
        "      for k in range(width - self.filter_size +1 ):\n",
        "        image_patch = image[j : (j + self.filter_size),k:(k + self.filter_size)]\n",
        "        yield image_patch, j ,k\n",
        "\n",
        "\n",
        "  def forward_prop(self, image):\n",
        "    height, width = image.shape\n",
        "    conv_out = np.zeros((height - self.filter_size+1, width -self.filter_size+1,self.num_filters ))\n",
        "    for image_patch,i,j in self.image_region(image):\n",
        "      conv_out[i,j]= np.sum(image_patch*self.conv_filter,axis = (1,2))\n",
        "    return conv_out\n",
        "\n",
        "  def back_prop(self,dL_dout,learning_rate):\n",
        "    dL_dF_params = np.zeros(self.conv_filter.shape)\n",
        "    for image_patch,i,j, in self.image_region(self.image):\n",
        "      for k in range(self.num_filters):\n",
        "        dL_dF_params[k] += image_patch*dL_dout[i,j,k]\n",
        "\n",
        "    self.conv_filter -= learning_rate*dL_dF_params\n",
        "    return dL_dF_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ap5O9Owbuiz"
      },
      "source": [
        "\n",
        "\n",
        "MAX POOL LAYER WITH BACK AND FORWARD PROP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P52uyeSZ1v-o"
      },
      "outputs": [],
      "source": [
        "class Max_pool:\n",
        "  def __init__(self,filter_size):\n",
        "    self.filter_size = filter_size\n",
        "\n",
        "  def image_region(self, image):\n",
        "    new_height = image.shape[0]//self.filter_size\n",
        "    new_width =  image.shape[1]//self.filter_size\n",
        "    self.image = image\n",
        "\n",
        "    for i in range(new_height):\n",
        "      for j in  range(new_width):\n",
        "        image_patch = image[(i*self.filter_size): (i*self.filter_size + self.filter_size),(j*self.filter_size):(j*self.filter_size + self.filter_size )]\n",
        "        yield image_patch , i,j\n",
        "\n",
        "  def forward_prop(self,image):\n",
        "    height,width, num_filters = image.shape\n",
        "    output = np.zeros((height // self.filter_size, width // self.filter_size , num_filters ))\n",
        "\n",
        "    for image_patch , i , j  in self.image_region(image):\n",
        "      output[i,j] = np.amax(image_patch, axis=(0,1))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "  def back_prop(self,dL_dout):\n",
        "    dL_dmax_pool = np.zeros(self.image.shape)\n",
        "    for image_patch, i,j in self.image_region(self.image):\n",
        "      height,width,num_filters =  image_patch.shape\n",
        "      maximum_val = np.amax(image_patch,axis=(0,1))\n",
        "\n",
        "      for i1 in range(height):\n",
        "        for j1 in range(width):\n",
        "          for k1 in range(num_filters):\n",
        "            if image_patch[i1,j1,k1] == maximum_val[k1]:\n",
        "              dL_dmax_pool[i*self.filter_size + i1, j*self.filter_size + j1,k1] = dL_dout[i,j,k1]\n",
        "\n",
        "      return dL_dmax_pool\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mILiHS8fcPfh"
      },
      "source": [
        "SIGMOID LAYER WITH FORWARD AND BACKWARD PROP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkLfFxGK1v1i"
      },
      "outputs": [],
      "source": [
        "class Softmax:\n",
        "  def __init__(self, input_node , softmax_node):\n",
        "    self.weight = np.random.randn(input_node , softmax_node)/input_node\n",
        "    self.bias = np.zeros(softmax_node)\n",
        "\n",
        "  def forward_prop(self, image):\n",
        "\n",
        "    self.orig_im_shape = image.shape\n",
        "    image_modified = image.flatten()\n",
        "    self.modified_input = image_modified\n",
        "    output_val = np.dot(image_modified,self.weight) + self.bias\n",
        "    self.out = output_val\n",
        "    exp_out = np.exp(output_val)\n",
        "    return exp_out/np.sum(exp_out , axis= 0)\n",
        "\n",
        "  def back_prop(self, dL_dout, learning_rate):\n",
        "    for i ,grad in enumerate(dL_dout):\n",
        "      if grad == 0:\n",
        "        continue\n",
        "\n",
        "      transformation_eq = np.exp(self.out)\n",
        "      S_total = np.sum(transformation_eq)\n",
        "\n",
        "      dy_dz= -transformation_eq[i]* transformation_eq /(S_total **2)\n",
        "      dy_dz[i] = transformation_eq[i]*(S_total - transformation_eq[i])/(S_total**2)\n",
        "\n",
        "      dz_dw = self.modified_input\n",
        "      dz_db = 1\n",
        "      dz_d_inp = self.weight\n",
        "\n",
        "      dL_dz = grad * dy_dz\n",
        "\n",
        "      dL_dw = dz_dw [np.newaxis].T @ dL_dz[np.newaxis]\n",
        "      dL_db = dL_dz * dz_db\n",
        "      dL_d_inp =  dz_d_inp @ dL_dz\n",
        "\n",
        "\n",
        "      self.weight -= learning_rate *dL_dw\n",
        "      self.bias -= learning_rate * dL_db\n",
        "      return dL_d_inp.reshape(self.orig_im_shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MisSh9gPcYMz"
      },
      "source": [
        "FINALLY DOWNLOADING THE MNIST DATA SET AND DOING THE TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train , y_train ) , (x_test , y_test) =  mnist.load_data()\n",
        "\n",
        "\n",
        "n = 500\n",
        "train_images =  x_train[:n]\n",
        "train_labels =  y_train[:n]\n",
        "test_images =  x_test[:n]\n",
        "test_labels = y_test[:n]"
      ],
      "metadata": {
        "id": "1bnMsNApNNkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[97])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "STYowiLiNNzv",
        "outputId": "de5bd6aa-b4cf-4614-eadd-b7b895c9f46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f239b6f61d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGFAGKfVNN1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdWVqS_jNN4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Vf26RbBYkd",
        "outputId": "27a826ed-7386-4f48-d0e1-0490a0bd7c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.370 and Accuracy: 0.090000%\n",
            "201 steps out of 500 steps: Average Loss  2.388 and Accuracy: 0.050000%\n",
            "301 steps out of 500 steps: Average Loss  2.356 and Accuracy: 0.090000%\n",
            "401 steps out of 500 steps: Average Loss  2.387 and Accuracy: 0.060000%\n",
            "14\n",
            "Epoch 2--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.365 and Accuracy: 0.120000%\n",
            "201 steps out of 500 steps: Average Loss  2.364 and Accuracy: 0.150000%\n",
            "301 steps out of 500 steps: Average Loss  2.318 and Accuracy: 0.190000%\n",
            "401 steps out of 500 steps: Average Loss  2.398 and Accuracy: 0.110000%\n",
            "6\n",
            "Epoch 3--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.396 and Accuracy: 0.070000%\n",
            "201 steps out of 500 steps: Average Loss  2.395 and Accuracy: 0.080000%\n",
            "301 steps out of 500 steps: Average Loss  2.402 and Accuracy: 0.070000%\n",
            "401 steps out of 500 steps: Average Loss  2.356 and Accuracy: 0.080000%\n",
            "13\n",
            "Epoch 4--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.352 and Accuracy: 0.080000%\n",
            "201 steps out of 500 steps: Average Loss  2.381 and Accuracy: 0.090000%\n",
            "301 steps out of 500 steps: Average Loss  2.330 and Accuracy: 0.160000%\n",
            "401 steps out of 500 steps: Average Loss  2.356 and Accuracy: 0.100000%\n",
            "10\n",
            "Epoch 5--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.352 and Accuracy: 0.140000%\n",
            "201 steps out of 500 steps: Average Loss  2.342 and Accuracy: 0.090000%\n",
            "301 steps out of 500 steps: Average Loss  2.313 and Accuracy: 0.130000%\n",
            "401 steps out of 500 steps: Average Loss  2.337 and Accuracy: 0.110000%\n",
            "13\n",
            "Epoch 6--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.347 and Accuracy: 0.130000%\n",
            "201 steps out of 500 steps: Average Loss  2.349 and Accuracy: 0.090000%\n",
            "301 steps out of 500 steps: Average Loss  2.345 and Accuracy: 0.110000%\n",
            "401 steps out of 500 steps: Average Loss  2.348 and Accuracy: 0.090000%\n",
            "10\n",
            "Epoch 7--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.327 and Accuracy: 0.110000%\n",
            "201 steps out of 500 steps: Average Loss  2.331 and Accuracy: 0.120000%\n",
            "301 steps out of 500 steps: Average Loss  2.332 and Accuracy: 0.130000%\n",
            "401 steps out of 500 steps: Average Loss  2.361 and Accuracy: 0.080000%\n",
            "13\n",
            "Epoch 8--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.378 and Accuracy: 0.090000%\n",
            "201 steps out of 500 steps: Average Loss  2.338 and Accuracy: 0.100000%\n",
            "301 steps out of 500 steps: Average Loss  2.349 and Accuracy: 0.090000%\n",
            "401 steps out of 500 steps: Average Loss  2.336 and Accuracy: 0.070000%\n",
            "9\n",
            "Epoch 9--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.311 and Accuracy: 0.170000%\n",
            "201 steps out of 500 steps: Average Loss  2.340 and Accuracy: 0.130000%\n",
            "301 steps out of 500 steps: Average Loss  2.350 and Accuracy: 0.090000%\n",
            "401 steps out of 500 steps: Average Loss  2.343 and Accuracy: 0.080000%\n",
            "15\n",
            "Epoch 10--->\n",
            "1 steps out of 500 steps: Average Loss  0.000 and Accuracy: 0.000000%\n",
            "101 steps out of 500 steps: Average Loss  2.331 and Accuracy: 0.110000%\n",
            "201 steps out of 500 steps: Average Loss  2.362 and Accuracy: 0.060000%\n",
            "301 steps out of 500 steps: Average Loss  2.379 and Accuracy: 0.080000%\n",
            "401 steps out of 500 steps: Average Loss  2.354 and Accuracy: 0.070000%\n",
            "8\n",
            "acc [2.8, 1.2, 2.6, 2.0, 2.6, 2.0, 2.6, 1.8, 3.0, 1.6]\n",
            "Testing Phase\n",
            "Test Loss: 2.33143455386631\n",
            "Test Accuracy: 10.0\n"
          ]
        }
      ],
      "source": [
        "conv = Conv_op (8,3)\n",
        "pool = Max_pool(2)\n",
        "softmax = Softmax(13*13*8,10)\n",
        "\n",
        "\n",
        "def cnn_forward_prop(image, label):\n",
        "\n",
        "  out_p = conv.forward_prop((image / 255)-0.5)\n",
        "  out_p  =  pool.forward_prop(out_p)\n",
        "  out_p = softmax.forward_prop(out_p)\n",
        "\n",
        "  cross_ent_loss = -np.log(out_p[label])\n",
        "  accuracy_eval = 1 if np.argmax(out_p) == label else 0\n",
        "\n",
        "  return out_p , cross_ent_loss , accuracy_eval\n",
        "\n",
        "\n",
        "def training_cnn(image,label,learn_rate= .005):\n",
        "\n",
        "  out,loss,acc = cnn_forward_prop(image, label)\n",
        "\n",
        "  gradient = np.zeros(10)\n",
        "  gradient[label] = -1/out[label]\n",
        "\n",
        "\n",
        "  grad_back = softmax.back_prop(gradient ,learn_rate)\n",
        "  grad_back = pool.back_prop(grad_back)\n",
        "  grad_back = conv.back_prop(grad_back, learn_rate)\n",
        "\n",
        "  return loss, acc\n",
        "\n",
        "\n",
        "accuracy_g = []\n",
        "for epoch1 in range(10):\n",
        "  print('Epoch %d--->'%(epoch1+1))\n",
        "\n",
        "  shuffle_data = np.random.permutation(len(train_images))\n",
        "  train_image = train_images[shuffle_data]\n",
        "  train_labels = train_labels[shuffle_data]\n",
        "\n",
        "  loss = 0\n",
        "  num_correct = 0\n",
        "  for i ,(im,label ) in enumerate(zip(train_image,train_labels)):\n",
        "    if i % 100 == 0:\n",
        "      print('%d steps out of %d steps: Average Loss  %.3f and Accuracy: %f%%' %(i+1,n,loss/100,num_correct/100))\n",
        "      loss=0\n",
        "      num_correct = 0\n",
        "\n",
        "    l1,accu = training_cnn(im, label)\n",
        "    loss+=l1\n",
        "    num_correct += accu\n",
        "  print(num_correct)\n",
        "  accuracy_g.append((num_correct*100)/n)\n",
        "\n",
        "\n",
        "print('acc', (accuracy_g))\n",
        "print('Testing Phase')\n",
        "loss= 0\n",
        "num_correct = 0\n",
        "for im, label in zip(test_images,test_labels):\n",
        "  _,l1,accu = cnn_forward_prop(im,label)\n",
        "  loss+=l1\n",
        "  num_correct+= accu\n",
        "\n",
        "\n",
        "num_tests = len(test_images)\n",
        "print('Test Loss:', (loss)/num_tests)\n",
        "print('Test Accuracy:',(num_correct*100)/num_tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS5LHZikGKAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}